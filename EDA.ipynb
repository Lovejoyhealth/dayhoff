{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samirchar/miniconda3/envs/dayhoff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sequence_models.utils import parse_fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FASTA file to dayhoffdata/uniref50_202401/consensus_sample.fasta\n",
      "Saved FASTA file to dayhoffdata/uniref50_202401/consensus_sample_no_annotations.fasta\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "def read_fasta(data_path: str,\n",
    "               sep: str =\" \",\n",
    "               ignore_labels = False,\n",
    "               n_seqs: int = None,\n",
    "               max_seq_length: int = None\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file and returns a list of tuples containing sequences, ids, and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    n_seqs = n_seqs if n_seqs is not None else float(\"inf\")\n",
    "    max_seq_length = max_seq_length if max_seq_length is not None else float(\"inf\")\n",
    "\n",
    "    sequences_with_ids_and_labels = []\n",
    "    for idx,record in enumerate(SeqIO.parse(data_path, \"fasta\")):\n",
    "        # If the sequence is too long, skip it\n",
    "        if len(record.seq) > max_seq_length:\n",
    "            continue\n",
    "\n",
    "        sequence = str(record.seq)\n",
    "        sequence_id = record.id\n",
    "\n",
    "\n",
    "        # always return dummy labels unless we are not ignoring the labels and the labels are present\n",
    "        labels = []\n",
    "        has_labels = False\n",
    "        \n",
    "        # labels[0] contains the sequence ID, and the rest of the labels are GO terms.\n",
    "        temp = record.description.split(sep)[1:] \n",
    "        has_labels = len(temp) > 0\n",
    "\n",
    "        if has_labels and not ignore_labels:\n",
    "            labels = temp\n",
    "\n",
    "        # Return a tuple of sequence, sequence_id, and labels\n",
    "        sequences_with_ids_and_labels.append((sequence, sequence_id, labels))\n",
    "\n",
    "        if len(sequences_with_ids_and_labels) >= n_seqs:\n",
    "            break\n",
    "\n",
    "    return sequences_with_ids_and_labels, has_labels\n",
    "\n",
    "\n",
    "def save_to_fasta(sequence_id_labels_tuples,\n",
    "                  output_file,\n",
    "                  no_annotations = False):\n",
    "    \"\"\"\n",
    "    Save a list of tuples in the form (sequence, [labels]) to a FASTA file.\n",
    "\n",
    "    :param sequence_label_tuples: List of tuples containing sequences and labels\n",
    "    :param output_file: Path to the output FASTA file\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "\n",
    "    for _, (\n",
    "        sequence,\n",
    "        id,\n",
    "        labels,\n",
    "    ) in enumerate(sequence_id_labels_tuples):\n",
    "        # Create a description from labels, joined by space\n",
    "        if no_annotations:\n",
    "            description = \"\"\n",
    "        else:\n",
    "            description = \" \".join(labels)\n",
    "\n",
    "        record = SeqRecord(Seq(sequence), id=id, description=description)\n",
    "        records.append(record)\n",
    "\n",
    "    # Write the SeqRecord objects to a FASTA file\n",
    "    with open(output_file, \"w\") as output_handle:\n",
    "        SeqIO.write(records, output_handle, \"fasta\")\n",
    "        print(\"Saved FASTA file to \" + output_file)\n",
    "\n",
    "#Create small sample faste for testing\n",
    "uniref_sample,_ =read_fasta('dayhoffdata/uniref50_202401/consensus.fasta',\n",
    "            n_seqs=10,\n",
    "            max_seq_length=2_048\n",
    "            )\n",
    "save_to_fasta(uniref_sample, output_file='dayhoffdata/uniref50_202401/consensus_sample.fasta')\n",
    "save_to_fasta(uniref_sample, output_file='dayhoffdata/uniref50_202401/consensus_sample_no_annotations.fasta',no_annotations=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, seq_names = parse_fasta('dayhoffdata/uniref50_202401/consensus_sample.fasta',return_names=True)\n",
    "seqs = {name.split()[0]:seq for name,seq in zip(seq_names,seqs)}\n",
    "selected = ['UniRef50_A0A401TRQ8','UniRef50_A0A7R8YPT0']\n",
    "selected_seqs = {k:seqs[k] for k in selected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running ESM Fold code\n",
    "\n",
    "#TODO: This is probably running in CPU.\n",
    "\n",
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "from transformers import AutoTokenizer, EsmForProteinFolding\n",
    "\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    outputs = {k: v.to(\"cpu\").numpy() for k, v in outputs.items()}\n",
    "    final_atom_positions = final_atom_positions.cpu().numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"]\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i]\n",
    "        pred_pos = final_atom_positions[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i] + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i],\n",
    "            chain_index=outputs[\"chain_index\"][i] if \"chain_index\" in outputs else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdbs\n",
    "\n",
    "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\")\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "model.esm = model.esm.half() #switch stem to half precision\n",
    "torch.backends.cuda.matmul.allow_tf32 = True #allower TensorFloat32 computation if HW supports it.\n",
    "model.trunk.set_chunk_size(64) # reduce chunk size of folding trunk. Less memory but slower.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
    "\n",
    "\n",
    "model_name = \"esmfold\"\n",
    "for seq_id,seq in selected_seqs.items():\n",
    "    inputs = tokenizer([seq], return_tensors=\"pt\", add_special_tokens=False)['input_ids'].cuda() \n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    pdb = convert_outputs_to_pdb(outputs)\n",
    "\n",
    "    with open(f\"dayhoffdata/uniref50_202401/pdb/{model_name}_{seq_id}.pdb\", \"w\") as f:\n",
    "        f.write(\"\".join(pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python fidelity.py --path_to_input_fasta ../dayhoffdata/uniref50_202401/consensus_sample.fasta --output_path ../dayhoffdata/uniref50_202401/ --fold_method omegafold --subbatch_size 20 --restart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dayhoff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
