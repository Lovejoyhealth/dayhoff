{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abfe7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_repo_files\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import CommitOperationCopy,CommitOperationDelete, create_commit\n",
    "\n",
    "repo_id = \"microsoft/Dayhoff\"\n",
    "repo_type = \"model\"\n",
    "\n",
    "load_dotenv()\n",
    "files = list_repo_files(repo_id, repo_type=repo_type,token=os.getenv(\"HF_TOKEN\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df864e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'170m-GGR',\n",
       " '170m-UR50',\n",
       " '170m-UR50-BBR-n',\n",
       " '170m-UR50-BBR-s',\n",
       " '170m-UR50-BBR-u',\n",
       " '170m-UR90',\n",
       " '3b-GGR-MSA',\n",
       " '3b-UR90',\n",
       " '3b-cooled'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i.split('/')[0] for i in files if \"gener\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9421c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old2new = {\n",
    " 'jamba-170m-10mnofilter-36w':'170m-UR50-BBR-u',\n",
    " 'jamba-170m-10mnovelty-36w':'170m-UR50-BBR-n',\n",
    " 'jamba-170m-gigaclust-36w':'170m-GGR',\n",
    " 'jamba-170m-seq-36w':'170m-UR50',\n",
    " 'jamba-170m-seqsam-36w':'170m-UR90',\n",
    " 'jamba-3b-cooldown7':'3b-cooled',\n",
    " 'jamba-3b-indel-gigaclust-120k-2':'3b-GGR-MSA',\n",
    " 'jamba-3b-seq-sam-biar-fsdp-tok90k':'3b-UR90',\n",
    " 'jamba-170m-10mrmsd-36w':'170m-UR50-BBR-s'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f06f4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 55188.21it/s]\n"
     ]
    }
   ],
   "source": [
    "copy_operations = []\n",
    "delete_operations = []\n",
    "\n",
    "files = [i for i in files if 'jamba-3b-seq-sam-biar-fsdp-tok90k' in i]\n",
    "for file in tqdm(files):\n",
    "    model_name = file.split('/')[0]\n",
    "    if model_name in model_old2new:\n",
    "        if model_old2new[model_name] == '':\n",
    "            continue\n",
    "        new_file = file.replace(model_name, model_old2new[model_name])\n",
    "        # print(file)\n",
    "        # print(new_file)\n",
    "        copy_operations.append(CommitOperationCopy(\n",
    "            src_path_in_repo =file,\n",
    "            path_in_repo =new_file\n",
    "        ))\n",
    "        delete_operations.append(CommitOperationDelete(\n",
    "            path_in_repo =file\n",
    "        ))\n",
    "        # print('=======')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee4ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 480111.11it/s]\n"
     ]
    }
   ],
   "source": [
    "delete_operations = []\n",
    "for file in tqdm(files):\n",
    "    if \"jamba\" in file:\n",
    "        delete_operations.append(CommitOperationDelete(\n",
    "            path_in_repo =file\n",
    "        ))\n",
    "        # print('=======')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76062780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/microsoft/dayhoff/commit/fe3732dcce88647d89c24953c1a58a8085f0992d', commit_message='Copy files to new model names', commit_description='', oid='fe3732dcce88647d89c24953c1a58a8085f0992d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/microsoft/dayhoff', endpoint='https://huggingface.co', repo_type='model', repo_id='microsoft/dayhoff'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_commit(\n",
    "    repo_id=repo_id,\n",
    "    operations=copy_operations,\n",
    "    commit_message=\"Copy files to new model names\",\n",
    "    token=os.environ.get(\"HF_TOKEN\"),\n",
    "    repo_type=repo_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/microsoft/dayhoff/commit/7ce25a90d4b8991cdc7f1dba0fa6e84da58587e7', commit_message='Delete old model names', commit_description='', oid='7ce25a90d4b8991cdc7f1dba0fa6e84da58587e7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/microsoft/dayhoff', endpoint='https://huggingface.co', repo_type='model', repo_id='microsoft/dayhoff'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_commit(\n",
    "    repo_id=repo_id,\n",
    "    operations=delete_operations,\n",
    "    commit_message=\"Delete old model names\",\n",
    "    token=os.environ.get(\"HF_TOKEN\"),\n",
    "    repo_type=repo_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe45c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jamba-170m-10mnofilter-36w': '170m-UR50-BBR-u',\n",
       " 'jamba-170m-10mnovelty-36w': '170m-UR50-BBR-n',\n",
       " 'jamba-170m-gigaclust-36w': '170m-GGR',\n",
       " 'jamba-170m-seq-36w': '170m-UR50',\n",
       " 'jamba-170m-seqsam-36w': '170m-UR90',\n",
       " 'jamba-3b-cooldown7': '3b-cooled',\n",
       " 'jamba-3b-indel-gigaclust-120k-2': '3b-GGR-MSA'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old2new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc91278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamba-170m-10mnofilter-36w (old): ['MATITDQPN']\n",
      "170m-UR50-BBR-u (new): ['MATITDQPN']\n",
      "jamba-170m-10mnovelty-36w (old): ['MATPADQPN']\n",
      "170m-UR50-BBR-n (new): ['MATPADQPN']\n",
      "jamba-170m-gigaclust-36w (old): ['LATPADQPR']\n",
      "170m-GGR (new): ['LATPADQPR']\n",
      "jamba-170m-seq-36w (old): ['MATIADQPN']\n",
      "170m-UR50 (new): ['MATIADQPN']\n",
      "jamba-170m-seqsam-36w (old): ['MATPADQPN']\n",
      "170m-UR90 (new): ['MATPADQPN']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "repo_id = \"microsoft/dayhoff\"\n",
    "max_length = 10\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id, trust_remote_code=True)\n",
    "\n",
    "for old,new in model_old2new.items():\n",
    "\n",
    "    if \"170\" not in old:\n",
    "        continue\n",
    "    set_seed(0)\n",
    "    #OLD\n",
    "    model = AutoModelForCausalLM.from_pretrained(repo_id, subfolder = old)\n",
    "    inputs = tokenizer(tokenizer.bos_token, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    outputs = model.generate(inputs['input_ids'],max_length=max_length,do_sample=True)\n",
    "    sequence = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "    print(f\"{old} (old): {sequence}\")\n",
    "\n",
    "    set_seed(0)\n",
    "    #NEW\n",
    "    model = AutoModelForCausalLM.from_pretrained(repo_id, subfolder = new)\n",
    "    inputs = tokenizer(tokenizer.bos_token, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    outputs = model.generate(inputs['input_ids'],max_length=max_length,do_sample=True)\n",
    "    sequence = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "    print(f\"{new} (new): {sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006b99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamba-170m-10mnovelty-36w (old): ['MATPADQPNLDLSTTSTDMTESYEPSEHVVKKTPKQNRKRKLDPMPEIEKETNEKNVEVEVKVKVKTETQREEQIIEEPPPVDDKMEVEVKEESATECD']\n",
      "170m-UR50-BBR-n (new): ['MATPADQPNLDLSTTSTDMTESYEPSEHVVKKTPKQNRKRKLDPMPEIEKETNEKNVEVEVKVKVKTETQREEQIIEEPPPVDDKMEVEVKEESATECD']\n",
      "True\n",
      "jamba-170m-seqsam-36w (old): ['MATPADQPNLDLSGTSTDMTESYEPSEHVVKKTPKQNRKGKLDPMPWILKSTNTKNVGVEVLDKLATETQREEQIIGCPPCRRDKCFKIRIEESATKCL']\n",
      "170m-UR90 (new): ['MATPADQPNLDLSGTSTDMTESYEPSEHVVKKTPKQNRKGKLDPMPWILKSTNTKNVGVEVLDKLATETQREEQIIGCPPCRRDKCFKIRIEESATKCL']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "repo_id = \"microsoft/dayhoff\"\n",
    "max_length = 100\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id, trust_remote_code=True)\n",
    "\n",
    "for old,new in model_old2new.items():\n",
    "\n",
    "    if old in [\"jamba-170m-10mnovelty-36w\",\"jamba-170m-seqsam-36w\"]:\n",
    "            \n",
    "        set_seed(0)\n",
    "        #OLD\n",
    "        model = AutoModelForCausalLM.from_pretrained(repo_id, subfolder = old)\n",
    "        inputs = tokenizer(tokenizer.bos_token, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "        outputs = model.generate(inputs['input_ids'],max_length=max_length,do_sample=True)\n",
    "        sequence_old = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "        print(f\"{old} (old): {sequence_old}\")\n",
    "\n",
    "        set_seed(0)\n",
    "        #NEW\n",
    "        model = AutoModelForCausalLM.from_pretrained(repo_id, subfolder = new)\n",
    "        inputs = tokenizer(tokenizer.bos_token, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "        outputs = model.generate(inputs['input_ids'],max_length=max_length,do_sample=True)\n",
    "        sequence_new = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "        print(f\"{new} (new): {sequence_new}\")\n",
    "        print(sequence_new == sequence_old)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dayhoff005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
